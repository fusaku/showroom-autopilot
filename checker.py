import time
import subprocess
import cx_Oracle
import os
import threading
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from config import *
from merger import merge_once
from datetime import datetime
from typing import Optional
from queue import Queue
from threading import Thread

os.environ["TNS_ADMIN"] = WALLET_DIR # æ–°å¢

# åœ¨å…¨å±€å˜é‡åŒºåŸŸæ·»åŠ 
merge_queue = Queue()  # åˆå¹¶ä»»åŠ¡é˜Ÿåˆ—
merge_lock = threading.Lock()  # åˆå¹¶é”ï¼ˆå¯é€‰ï¼ŒQueueæœ¬èº«æ˜¯çº¿ç¨‹å®‰å…¨çš„ï¼‰

# ========================= æ–‡ä»¶å¤¹æ“ä½œ =========================

def find_all_live_folders(parent_dir: Path):
    """è·å–æ‰€æœ‰ç›´æ’­æ–‡ä»¶å¤¹è·¯å¾„"""
    folders = []
    for f in parent_dir.iterdir():
        if f.is_dir() and not f.name.startswith("temp_"):  # æ’é™¤ä¸´æ—¶ç›®å½•
            folders.append(f)
    return sorted(folders, key=lambda x: x.stat().st_mtime)


def find_latest_live_folder(parent_dir: Path):
    """è·å–æœ€æ–°åˆ›å»ºçš„ç›´æ’­æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰"""
    folders = [f for f in parent_dir.iterdir() if f.is_dir()]
    return max(folders, key=lambda x: x.stat().st_mtime, default=None)


def has_been_merged(ts_dir: Path):
    """åˆ¤æ–­è¯¥ç›´æ’­æ˜¯å¦å·²ç»åˆå¹¶è¿‡"""
    return (ts_dir / FILELIST_NAME).exists()


def has_files_to_check(ts_dir: Path):
    """æ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ–‡ä»¶å¯ä»¥å¼€å§‹æ£€æŸ¥"""
    ts_files = list(ts_dir.glob("*.ts"))
    return len(ts_files) >= MIN_FILES_FOR_CHECK


def all_folders_completed(folders):
    """æ£€æŸ¥æ‰€æœ‰æ–‡ä»¶å¤¹æ˜¯å¦éƒ½å·²å®Œæˆæ£€æŸ¥ï¼ˆéƒ½æœ‰filelist.txtï¼‰"""
    if not folders:
        return False
    return all(has_been_merged(folder) for folder in folders)


# ========================= æ–‡ä»¶çŠ¶æ€æ£€æŸ¥ =========================
def group_folders_by_member(folders):
    """å°†æ–‡ä»¶å¤¹æŒ‰æˆå‘˜åˆ†ç»„,æ ¹æ®tsæ–‡ä»¶æ—¶é—´æˆ³åˆ¤æ–­æ˜¯å¦ä¸ºåŒä¸€åœºç›´æ’­(æ”¯æŒè·¨æ—¥)"""
    from collections import defaultdict
    groups = defaultdict(list)
    
    # å…ˆæŒ‰æˆå‘˜IDåˆ†ç»„
    member_folders = defaultdict(list)
    for folder in folders:
        member_id = extract_member_name_from_folder(folder.name)
        if member_id:
            member_folders[member_id].append(folder)
        else:
            # è§£æå¤±è´¥çš„å•ç‹¬åˆ†ç»„
            groups[f"unknown_{folder.name}"].append(folder)
    
    # å¯¹æ¯ä¸ªæˆå‘˜çš„æ–‡ä»¶å¤¹æŒ‰åˆ›å»ºæ—¶é—´æ’åº,ç„¶åæ ¹æ®tsæ–‡ä»¶æ—¶é—´åˆ¤æ–­æ˜¯å¦è¿ç»­
    for member_id, member_folder_list in member_folders.items():
        # æŒ‰æ–‡ä»¶å¤¹åˆ›å»ºæ—¶é—´æ’åº
        member_folder_list.sort(key=lambda x: x.stat().st_ctime)
        
        if not member_folder_list:
            continue
            
        # ç”¨äºæ ‡è®°å½“å‰ç›´æ’­ç»„
        current_group = []
        group_index = 0
        
        for i, folder in enumerate(member_folder_list):
            if i == 0:
                # ç¬¬ä¸€ä¸ªæ–‡ä»¶å¤¹,ç›´æ¥åŠ å…¥å½“å‰ç»„
                current_group.append(folder)
            else:
                # è·å–å½“å‰æ–‡ä»¶å¤¹æœ€æ—©çš„tsæ–‡ä»¶æ—¶é—´
                current_ts_files = list(folder.glob("*.ts"))
                if not current_ts_files:
                    # æ²¡æœ‰tsæ–‡ä»¶,æŒ‰æ–‡ä»¶å¤¹æ—¶é—´åˆ¤æ–­(é™çº§å¤„ç†)
                    prev_folder = member_folder_list[i-1]
                    time_diff = folder.stat().st_ctime - prev_folder.stat().st_ctime
                    if time_diff < 14400:  # 4å°æ—¶
                        current_group.append(folder)
                    else:
                        # ä¿å­˜å½“å‰ç»„å¹¶å¼€å§‹æ–°ç»„
                        first_folder = current_group[0]
                        date_part = first_folder.name[:6]
                        key = f"{date_part}_{member_id}_{group_index}"
                        groups[key] = current_group
                        group_index += 1
                        current_group = [folder]
                    continue
                
                current_earliest_ts = min(current_ts_files, key=lambda x: x.stat().st_ctime)
                current_ts_time = current_earliest_ts.stat().st_ctime
                
                # è·å–å‰ä¸€ä¸ªæ–‡ä»¶å¤¹æœ€æ™šçš„tsæ–‡ä»¶æ—¶é—´
                prev_folder = current_group[-1]  # ç”¨å½“å‰ç»„çš„æœ€åä¸€ä¸ªæ–‡ä»¶å¤¹
                prev_ts_files = list(prev_folder.glob("*.ts"))
                
                if prev_ts_files:
                    prev_latest_ts = max(prev_ts_files, key=lambda x: x.stat().st_ctime)
                    prev_ts_time = prev_latest_ts.stat().st_ctime
                    
                    # è®¡ç®—ä¸¤ä¸ªæ–‡ä»¶å¤¹tsæ–‡ä»¶çš„æ—¶é—´å·®
                    time_gap = current_ts_time - prev_ts_time
                    
                    # å¦‚æœæ—¶é—´å·®å°äº5åˆ†é’Ÿ(300ç§’),è®¤ä¸ºæ˜¯åŒä¸€åœºç›´æ’­
                    # æ­£å¸¸æƒ…å†µä¸‹tsæ–‡ä»¶æ¯2ç§’ä¸€ä¸ª,5åˆ†é’Ÿå·²ç»å¾ˆå®½æ¾äº†
                    if time_gap < 300:
                        current_group.append(folder)
                        if DEBUG_MODE:
                            log(f"æ–‡ä»¶å¤¹ {folder.name} ä¸å‰ä¸€ä¸ªæ–‡ä»¶å¤¹tsæ—¶é—´å·® {time_gap:.0f}ç§’,åˆ¤å®šä¸ºåŒä¸€åœºç›´æ’­")
                    else:
                        # æ—¶é—´å·®å¤ªå¤§,è¯´æ˜æ˜¯æ–°çš„ç›´æ’­
                        if DEBUG_MODE:
                            log(f"æ–‡ä»¶å¤¹ {folder.name} ä¸å‰ä¸€ä¸ªæ–‡ä»¶å¤¹tsæ—¶é—´å·® {time_gap:.0f}ç§’,åˆ¤å®šä¸ºæ–°ç›´æ’­")
                        
                        # ä¿å­˜å½“å‰ç»„
                        first_folder = current_group[0]
                        date_part = first_folder.name[:6]
                        key = f"{date_part}_{member_id}_{group_index}"
                        groups[key] = current_group
                        
                        # å¼€å§‹æ–°ç»„
                        group_index += 1
                        current_group = [folder]
                else:
                    # å‰ä¸€ä¸ªæ–‡ä»¶å¤¹æ²¡æœ‰tsæ–‡ä»¶,é™çº§åˆ°æ–‡ä»¶å¤¹æ—¶é—´åˆ¤æ–­
                    time_diff = folder.stat().st_ctime - prev_folder.stat().st_ctime
                    if time_diff < 14400:
                        current_group.append(folder)
                    else:
                        first_folder = current_group[0]
                        date_part = first_folder.name[:6]
                        key = f"{date_part}_{member_id}_{group_index}"
                        groups[key] = current_group
                        group_index += 1
                        current_group = [folder]
        
        # ä¿å­˜æœ€åä¸€ç»„
        if current_group:
            first_folder = current_group[0]
            date_part = first_folder.name[:6]
            key = f"{date_part}_{member_id}_{group_index}"
            groups[key] = current_group
    
    return groups

def has_matching_subtitle_for_group(group_folders):
    """æ£€æŸ¥ä¸€ç»„æ–‡ä»¶å¤¹(åŒä¸€ä¸ªç›´æ’­)æ˜¯å¦æœ‰å¯¹åº”çš„å­—å¹•æ–‡ä»¶
    
    åªéœ€è¦æ£€æŸ¥ç»„å†…æœ€æ—©çš„æ–‡ä»¶å¤¹,å› ä¸ºå­—å¹•æ˜¯æŒ‰ç›´æ’­ç”Ÿæˆçš„,ä¸æ˜¯æŒ‰æ–‡ä»¶å¤¹
    """
    if not group_folders:
        return False
    
    # å–æœ€æ—©çš„æ–‡ä»¶å¤¹ä½œä¸ºä»£è¡¨
    earliest_folder = min(group_folders, key=lambda x: x.stat().st_ctime)
    return has_matching_subtitle_file(earliest_folder)

def is_file_stable(file_path: Path, stable_time: int = FILE_STABLE_TIME):
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ç¨³å®šï¼ˆåœ¨æŒ‡å®šæ—¶é—´å†…æ²¡æœ‰è¢«ä¿®æ”¹ï¼‰"""
    if not file_path.exists():
        return False
    time_since_modified = time.time() - file_path.stat().st_mtime
    return time_since_modified > stable_time


def is_live_active(ts_dir: Path):
    """æ£€æŸ¥ç›´æ’­æ˜¯å¦è¿˜åœ¨è¿›è¡Œä¸­"""
    ts_files = list(ts_dir.glob("*.ts"))
    if not ts_files:
        return False
    
    latest_mtime = max(f.stat().st_mtime for f in ts_files)
    seconds_since_last_update = time.time() - latest_mtime
    return seconds_since_last_update <= LIVE_INACTIVE_THRESHOLD


def is_really_stream_ended(all_folders, grace_period=FINAL_INACTIVE_THRESHOLD):
    """ç»¼åˆåˆ¤æ–­ç›´æ’­æ˜¯å¦çœŸæ­£ç»“æŸ - æ£€æŸ¥æ‰€æœ‰æ–‡ä»¶å¤¹çš„æ–‡ä»¶æ´»è·ƒåº¦"""
    current_time = time.time()
    
    for ts_dir in all_folders:
        ts_files = list(ts_dir.glob("*.ts"))
        if not ts_files:
            continue
            
        # è·å–è¯¥æ–‡ä»¶å¤¹æœ€æ–°æ–‡ä»¶çš„ä¿®æ”¹æ—¶é—´
        latest_mtime = max(f.stat().st_mtime for f in ts_files)
        seconds_since_last_update = current_time - latest_mtime
        
        # å¦‚æœä»»ä½•æ–‡ä»¶å¤¹çš„æ–‡ä»¶åœ¨å®½é™æœŸå†…è¿˜æœ‰æ›´æ–°ï¼Œè¯´æ˜å¯èƒ½è¿˜åœ¨å½•åˆ¶
        if seconds_since_last_update <= grace_period:
            if DEBUG_MODE:
                log(f"æ–‡ä»¶å¤¹ {ts_dir.name} åœ¨ {seconds_since_last_update:.0f} ç§’å‰è¿˜æœ‰æ–‡ä»¶æ›´æ–°ï¼Œå¯èƒ½è¿˜åœ¨å½•åˆ¶ä¸­")
            return False
    
    return True

def has_matching_subtitle_file(ts_dir: Path):
    """æ£€æŸ¥æŒ‡å®šæ–‡ä»¶å¤¹æ˜¯å¦æœ‰å¯¹åº”çš„å­—å¹•æ–‡ä»¶ï¼Œæ”¯æŒè‡ªåŠ¨å¤„ç†ä¸åŒ¹é…æƒ…å†µ"""
    if not ts_dir:
        return False
    
    folder_name = ts_dir.name
    
    try:
        date_part = folder_name[:6]  # å–å‰6ä½ä½œä¸ºæ—¥æœŸ
        # è½¬æ¢ä¸ºå®Œæ•´æ—¥æœŸæ ¼å¼ 250826 -> 2025-08-26
        year = "20" + date_part[:2]
        month = date_part[2:4]
        day = date_part[4:6]
        date_folder = f"{year}-{month}-{day}"
        
        # æ„å»ºå­—å¹•æ–‡ä»¶è·¯å¾„
        subtitle_dir = SUBTITLE_ROOT / date_folder / SUBTITLE_SUBPATH
        exact_subtitle = subtitle_dir / f"{folder_name}.ass"
        
        # é¦–å…ˆæ£€æŸ¥ç²¾ç¡®åŒ¹é…
        if exact_subtitle.exists():
            return True
        
        # å¦‚æœç²¾ç¡®åŒ¹é…å¤±è´¥,æå–äººåè¿›è¡Œæ¨¡ç³ŠåŒ¹é…
        # ä»æ–‡ä»¶å¤¹åç§°ä¸­æå–äººåéƒ¨åˆ†
        # æ ¼å¼: "æ—¥æœŸ Showroom - å›¢é˜Ÿä¿¡æ¯ äººå æ—¶é—´æˆ³"
        try:
            # åˆ†å‰²æ–‡ä»¶å¤¹å,æå–å…³é”®éƒ¨åˆ†
            parts = folder_name.split(" - ")
            if len(parts) >= 2:
                # parts[1] åº”è¯¥æ˜¯ "AKB48 Team 8 Hashimoto Haruna 064348"
                name_parts = parts[1].split()
                
                # æŸ¥æ‰¾äººå:é€šå¸¸æ˜¯æœ€åä¸¤ä¸ªå•è¯(å§“æ° åå­—),ä½†è¦æ’é™¤æ—¶é—´æˆ³
                # æ—¶é—´æˆ³æ ¼å¼æ˜¯6ä½æ•°å­—
                filtered_parts = [p for p in name_parts if not (p.isdigit() and len(p) == 6)]
                
                # å¦‚æœæœ‰è¶³å¤Ÿçš„éƒ¨åˆ†,å–æœ€åä¸¤ä¸ªä½œä¸ºäººå
                if len(filtered_parts) >= 2:
                    # å§“æ°å’Œåå­—
                    last_name = filtered_parts[-2]
                    first_name = filtered_parts[-1]
                    name_pattern = f"{last_name} {first_name}"
                else:
                    name_pattern = None
            else:
                name_pattern = None
                
        except Exception as e:
            if DEBUG_MODE:
                log(f"è§£æäººåå¤±è´¥: {folder_name}, é”™è¯¯: {e}")
            name_pattern = None
        
        # å¦‚æœæˆåŠŸæå–äººå,åœ¨åŒä¸€å¤©çš„å­—å¹•æ–‡ä»¶ä¸­æŸ¥æ‰¾åŒ…å«è¯¥äººåçš„æ–‡ä»¶
        if name_pattern and subtitle_dir.exists():
            # å…ˆå°è¯•ç²¾ç¡®åŒ¹é…äººå
            subtitle_files = list(subtitle_dir.glob(f"{date_part} Showroom*{name_pattern}*.ass"))
            
            # å¦‚æœæ²¡æ‰¾åˆ°,å°è¯•åªç”¨å§“æ°åŒ¹é…
            if not subtitle_files and len(filtered_parts) >= 2:
                last_name = filtered_parts[-2]
                subtitle_files = list(subtitle_dir.glob(f"{date_part} Showroom*{last_name}*.ass"))
            
            if subtitle_files:
                # æ‰¾åˆ°åŒ¹é…çš„å­—å¹•æ–‡ä»¶,è‡ªåŠ¨åˆ›å»ºè½¯é“¾æ¥
                source_subtitle = subtitle_files[0]  # å–ç¬¬ä¸€ä¸ªåŒ¹é…çš„
                log(f"æ£€æµ‹åˆ°å­—å¹•æ–‡ä»¶ä¸åŒ¹é…æƒ…å†µ:")
                log(f"  è§†é¢‘æ–‡ä»¶å¤¹: {folder_name}")
                log(f"  å­—å¹•æ–‡ä»¶: {source_subtitle.name}")
                log(f"  åŒ¹é…æ¨¡å¼: {name_pattern}")
                log(f"  è‡ªåŠ¨åˆ›å»ºåŒ¹é…çš„å­—å¹•æ–‡ä»¶...")
                
                try:
                    # åˆ›å»ºè½¯é“¾æ¥
                    exact_subtitle.symlink_to(source_subtitle)
                    log(f"âœ“ æˆåŠŸåˆ›å»ºè½¯é“¾æ¥: {exact_subtitle.name}")
                    return True
                except FileExistsError:
                    # è½¯é“¾æ¥å·²å­˜åœ¨,ç›´æ¥è¿”å›True
                    log(f"âœ“ è½¯é“¾æ¥å·²å­˜åœ¨: {exact_subtitle.name}")
                    return True
                except Exception as e:
                    log(f"âœ— åˆ›å»ºè½¯é“¾æ¥å¤±è´¥: {e}")
                    return False
        
        return False
        
    except Exception as e:
        if DEBUG_MODE:
            log(f"è§£ææ–‡ä»¶å¤¹æ—¥æœŸå¤±è´¥: {folder_name}, é”™è¯¯: {e}")
        return False

def get_earliest_active_folder(all_folders):
    """è·å–æœ€æ—©çš„æ´»è·ƒæ–‡ä»¶å¤¹ï¼ˆå½“å‰å½•åˆ¶ä¸­ä¸”æœ‰æ–‡ä»¶çš„æ–‡ä»¶å¤¹ä¸­æœ€æ—©åˆ›å»ºçš„ï¼‰"""
    active_folders = []
    for folder in all_folders:
        ts_files = list(folder.glob("*.ts"))
        # å¿…é¡»åŒæ—¶æ»¡è¶³ï¼šæœ‰æ–‡ä»¶ + è¿˜åœ¨å½•åˆ¶ä¸­ï¼ˆæ–‡ä»¶è¿˜åœ¨æ´»è·ƒï¼‰
        if ts_files and is_live_active(folder):
            active_folders.append(folder)
    
    if not active_folders:
        return None
    
    # è¿”å›åˆ›å»ºæ—¶é—´æœ€æ—©çš„æ–‡ä»¶å¤¹
    return min(active_folders, key=lambda x: x.stat().st_ctime)

# ========================= ç½‘ç»œçŠ¶æ€æ£€æŸ¥ (æ•°æ®åº“) =========================

def read_is_live(member_id: str):
    """ä»æ•°æ®åº“è¯»å–æŒ‡å®šæˆå‘˜çš„ç›´æ’­çŠ¶æ€ (æ¯æ¬¡æ“ä½œå»ºç«‹æ–°è¿æ¥)"""
    
    # æ¯æ¬¡è°ƒç”¨æ—¶ï¼Œåœ¨ try å—å†…å»ºç«‹å’Œå…³é—­è¿æ¥ï¼Œç¡®ä¿è¿æ¥æœ‰æ•ˆæ€§å’Œèµ„æºé‡Šæ”¾
    try:
        # ä½¿ç”¨ 'with' è¯­å¥ä¿è¯è¿æ¥å’Œæ¸¸æ ‡è‡ªåŠ¨å…³é—­
        with cx_Oracle.connect(user=DB_USER, password=DB_PASSWORD, dsn=TNS_ALIAS) as conn:
            with conn.cursor() as cursor:
                # æŸ¥è¯¢æŒ‡å®šæˆå‘˜çš„çŠ¶æ€
                query = f"""
                    SELECT IS_LIVE
                    FROM {DB_TABLE}
                    WHERE MEMBER_ID = :member_id
                """
                
                cursor.execute(query, {'member_id': member_id})
                result = cursor.fetchone()
                
                if result:
                    # IS_LIVE å­—æ®µ (1=True, 0=False)
                    is_live = bool(result[0])
                    if VERBOSE_LOGGING:
                        log(f"ä»æ•°æ®åº“è¯»å–çŠ¶æ€: æˆå‘˜ {member_id}, is_live={is_live}")
                    return is_live
                else:
                    if VERBOSE_LOGGING:
                        log(f"æ•°æ®åº“ä¸­æœªæ‰¾åˆ°æˆå‘˜ {member_id} çš„è®°å½•")
                    return False
            
    except Exception as e:
        # æ•è·è¿æ¥å¤±è´¥æˆ–æŸ¥è¯¢å¤±è´¥çš„é”™è¯¯
        log(f"ä»æ•°æ®åº“è¯»å–çŠ¶æ€å¤±è´¥: {e}")
        return False

def extract_member_name_from_folder(folder_name: str) -> Optional[str]:
    """ä»æ–‡ä»¶å¤¹åç§°ä¸­æå–äººåéƒ¨åˆ†ï¼Œç”¨äºæ¨¡ç³ŠåŒ¹é…æ•°æ®åº“ä¸­çš„ member_id"""
    try:
        # æ–‡ä»¶å¤¹æ ¼å¼: "æ—¥æœŸ Showroom - å›¢é˜Ÿä¿¡æ¯ äººå æ—¶é—´æˆ³"
        parts = folder_name.split(" - ")
        if len(parts) >= 2:
            # parts[1] åº”è¯¥æ˜¯ "AKB48 Team 8 Hashimoto Haruna 233156"
            name_parts = parts[1].split()
            
            # è¿‡æ»¤æ‰æ—¶é—´æˆ³ (6ä½æ•°å­—)
            filtered_parts = [p for p in name_parts if not (p.isdigit() and len(p) == 6)]
            
            # é€šå¸¸äººåæ˜¯æœ€åä¸¤ä¸ªå•è¯ (å§“ åå­—)
            if len(filtered_parts) >= 2:
                # æ‹¼æ¥æˆ "hashimoto_haruna" æ ¼å¼ (æ³¨æ„æ•°æ®åº“ä¸­çš„æ ¼å¼)
                last_name = filtered_parts[-2].lower()
                first_name = filtered_parts[-1].lower()
                
                # å°è¯•ä½¿ç”¨ "å§“_å" æ ¼å¼åŒ¹é…æ•°æ®åº“ID
                return f"{last_name}_{first_name}"
                
            # å¦‚æœåªæœ‰ä¸€ä¸ªäººåéƒ¨åˆ†ï¼Œåˆ™è¿”å›è¯¥éƒ¨åˆ†
            elif len(filtered_parts) == 1:
                return filtered_parts[-1].lower()

    except Exception as e:
        if DEBUG_MODE:
            log(f"è§£æäººåå¤±è´¥: {folder_name}, é”™è¯¯: {e}")
            
    return None

# ========================= æ–‡ä»¶æ£€æŸ¥å’Œå¤„ç† =========================

def check_ts_file(ts_file: Path):
    """æ£€æµ‹tsæ–‡ä»¶æ˜¯å¦å«è§†é¢‘å’ŒéŸ³é¢‘æµ"""
    # æ„å»ºFFprobeå‘½ä»¤ï¼Œä½¿ç”¨é…ç½®çš„å‚æ•°
    base_cmd = ["ffprobe"]
    
    # æ·»åŠ éšè—banneré€‰é¡¹
    if FFMPEG_HIDE_BANNER:
        base_cmd.append("-hide_banner")
    
    # æ·»åŠ æ—¥å¿—çº§åˆ«
    base_cmd.extend(["-v", FFMPEG_LOGLEVEL])
    
    v_cmd = base_cmd + [
        "-select_streams", "v",
        "-show_entries", "stream=index",
        "-of", "csv=p=0",
        str(ts_file)
    ]
    a_cmd = base_cmd + [
        "-select_streams", "a",
        "-show_entries", "stream=index",
        "-of", "csv=p=0",
        str(ts_file)
    ]
    
    try:
        video_stream = subprocess.run(
            v_cmd, 
            stdout=subprocess.PIPE, 
            stderr=subprocess.PIPE, 
            text=True, 
            timeout=FFPROBE_TIMEOUT
        ).stdout.strip()
        
        audio_stream = subprocess.run(
            a_cmd, 
            stdout=subprocess.PIPE, 
            stderr=subprocess.PIPE, 
            text=True, 
            timeout=FFPROBE_TIMEOUT
        ).stdout.strip()
        
        if video_stream and audio_stream:
            return ts_file, None
        else:
            msg = f"[ä¸åŒæ­¥æˆ–ç¼ºæµ] {ts_file.name}"
            return None, msg
    except Exception as e:
        return None, f"[é”™è¯¯] {ts_file.name} æ£€æµ‹å¤±è´¥: {e}"


def get_unchecked_stable_files(ts_dir: Path, checked_files: set):
    """è·å–æœªæ£€æŸ¥ä¸”ç¨³å®šçš„tsæ–‡ä»¶"""
    ts_files = list(ts_dir.glob("*.ts"))
    unchecked_files = []
    
    for ts_file in ts_files:
        # å¦‚æœæ–‡ä»¶è¿˜æ²¡æ£€æŸ¥è¿‡ä¸”å·²ç»ç¨³å®š
        if ts_file not in checked_files and is_file_stable(ts_file):
            unchecked_files.append(ts_file)
    
    return unchecked_files


def check_live_folder_incremental(ts_dir: Path, checked_files: set, valid_files: list, error_logs: list):
    """å¢é‡æ£€æŸ¥ç›´æ’­æ–‡ä»¶å¤¹ä¸­çš„æ–°æ–‡ä»¶"""
    base_name = ts_dir.name
    
    # è·å–æœªæ£€æŸ¥ä¸”ç¨³å®šçš„æ–‡ä»¶
    unchecked_files = get_unchecked_stable_files(ts_dir, checked_files)
    
    if not unchecked_files:
        return
    
    if DEBUG_MODE or VERBOSE_LOGGING:
        log(f"[{base_name}] å‘ç° {len(unchecked_files)} ä¸ªæ–°çš„ç¨³å®šæ–‡ä»¶éœ€è¦æ£€æŸ¥")
    
    # æ£€æŸ¥æ–°æ–‡ä»¶
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(check_ts_file, f): f for f in unchecked_files}
        for future in as_completed(futures):
            ts_file = futures[future]
            valid_file, err_msg = future.result()
            
            # æ ‡è®°ä¸ºå·²æ£€æŸ¥
            checked_files.add(ts_file)
            
            if valid_file:
                valid_files.append(valid_file)
                if DEBUG_MODE:
                    log(f"[{base_name}] âœ“ {ts_file.name}")
            if err_msg:
                log(f"[{base_name}] {err_msg}")
                error_logs.append(err_msg)


def finalize_live_check(ts_dir: Path, checked_files: set, valid_files: list, error_logs: list):
    """ç›´æ’­ç»“æŸåçš„æœ€ç»ˆæ£€æŸ¥å’Œæ–‡ä»¶åˆ—è¡¨ç”Ÿæˆ"""
    base_name = ts_dir.name
    filelist_txt = ts_dir / FILELIST_NAME
    log_file = OUTPUT_DIR / f"{base_name}{LOG_SUFFIX}"
    
    # æ£€æŸ¥å‰©ä½™æœªæ£€æŸ¥çš„æ–‡ä»¶ï¼ˆåŒ…æ‹¬ä¸ç¨³å®šçš„ï¼‰
    ts_files = list(ts_dir.glob("*.ts"))
    unchecked_files = [f for f in ts_files if f not in checked_files]
    
    if unchecked_files:
        log(f"[{base_name}] æœ€ç»ˆæ£€æŸ¥å‰©ä½™ {len(unchecked_files)} ä¸ªæ–‡ä»¶")
        
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            futures = {executor.submit(check_ts_file, f): f for f in unchecked_files}
            for future in as_completed(futures):
                ts_file = futures[future]
                valid_file, err_msg = future.result()
                
                if valid_file:
                    valid_files.append(valid_file)
                if err_msg:
                    log(f"[{base_name}] {err_msg}")
                    error_logs.append(err_msg)
    
    # æŒ‰æ–‡ä»¶åæ’åº
    valid_files.sort()
    
    # å†™ filelist.txtï¼šæ— è®ºæ˜¯å¦æœ‰æœ‰æ•ˆæ–‡ä»¶ï¼Œéƒ½éœ€è¦åˆ›å»ºè¿™ä¸ªæ–‡ä»¶ä½œä¸ºæ£€æŸ¥å®Œæˆçš„æ ‡è®°
    with open(filelist_txt, "w", encoding="utf-8") as f:
        if valid_files:
            # å¦‚æœæœ‰æœ‰æ•ˆæ–‡ä»¶ï¼Œå†™å…¥åˆ—è¡¨
            for vf in valid_files:
                f.write(f"file '{vf.resolve()}'\n")
            log(f"[{base_name}] æ£€æŸ¥å®Œæˆï¼Œå…± {len(valid_files)} ä¸ªæœ‰æ•ˆæ–‡ä»¶")
            result_success = True
        else:
            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆæ–‡ä»¶ï¼Œå†™å…¥ä¸€ä¸ªæ ‡è®°æ³¨é‡Šï¼Œé˜²æ­¢åç»­å¾ªç¯é‡å¤æ£€æŸ¥
            f.write(f"# No valid .ts files found. Marked as checked at {datetime.now()}\n")
            log(f"[{base_name}] æ²¡æœ‰æœ‰æ•ˆçš„ .ts æ–‡ä»¶ï¼Œå·²æ ‡è®°ä¸ºæ£€æŸ¥å®Œæˆã€‚")
            result_success = False
    
    # å†™æ—¥å¿—æ–‡ä»¶
    if error_logs or not result_success: # å¦‚æœæœ‰é”™è¯¯æˆ–ç»“æœå¤±è´¥ï¼Œéƒ½å†™æ—¥å¿—
        OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
        with open(log_file, "w", encoding="utf-8") as logf:
            logf.write(f"æ£€æµ‹æ—¶é—´ï¼š{datetime.now()}\n")
            logf.write(f"æ€»æ–‡ä»¶æ•°ï¼š{len(ts_files)}\n")
            logf.write(f"æœ‰æ•ˆæ–‡ä»¶æ•°ï¼š{len(valid_files)}\n")
            logf.write(f"é”™è¯¯æ–‡ä»¶æ•°ï¼š{len(error_logs)}\n\n")
            if not result_success:
                 logf.write("æ­¤æ–‡ä»¶å¤¹ä¸­æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„è§†é¢‘æµæ–‡ä»¶ï¼Œå·²å¼ºåˆ¶æ ‡è®°å®Œæˆã€‚\n\n")
            logf.write("\n".join(error_logs))
        log(f"[{base_name}] å­˜åœ¨å¼‚å¸¸/ä¸ºç©ºï¼Œæ—¥å¿—å†™å…¥ï¼š{log_file}")
    
    # è¿”å›çš„æ˜¯æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°äº†æœ‰æ•ˆæ–‡ä»¶
    return result_success


# ========================= æ–‡ä»¶å¤¹å¤„ç†é€»è¾‘ =========================

def process_single_folder(ts_dir: Path, folder_states: dict, all_folders: list, current_time: float):
    """å¤„ç†å•ä¸ªæ–‡ä»¶å¤¹çš„æ£€æŸ¥é€»è¾‘"""
    base_name = ts_dir.name
    
    # åˆå§‹åŒ–æ–‡ä»¶å¤¹çŠ¶æ€
    if ts_dir not in folder_states:
        folder_states[ts_dir] = {
            'checked_files': set(),
            'valid_files': [],
            'error_logs': [],
            'last_check': 0,
            'creation_time': current_time
        }
    
    state = folder_states[ts_dir]
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»å®Œæˆæ£€æŸ¥
    if has_been_merged(ts_dir):
        if DEBUG_MODE:
            log(f"ç›´æ’­ {base_name} å·²æ£€æŸ¥å®Œæˆï¼Œè·³è¿‡")
        return True  # è¿”å›Trueè¡¨ç¤ºè¯¥æ–‡ä»¶å¤¹å·²å®Œæˆ
    
    # æ£€æŸ¥æ–‡ä»¶æ•°é‡æ˜¯å¦è¶³å¤Ÿå¼€å§‹æ£€æŸ¥
    if not has_files_to_check(ts_dir):
        if DEBUG_MODE:
            ts_count = len(list(ts_dir.glob("*.ts")))
            log(f"ç›´æ’­ {base_name} æ–‡ä»¶æ•°é‡ä¸è¶³({ts_count}/{MIN_FILES_FOR_CHECK})ï¼Œç­‰å¾…ä¸­...")
        return False  # è¿”å›Falseè¡¨ç¤ºè¯¥æ–‡ä»¶å¤¹è¿˜ä¸èƒ½å¤„ç†
    
    # ç›´æ’­è¿›è¡Œä¸­ - å¢é‡æ£€æŸ¥ç¨³å®šçš„æ–‡ä»¶
    if current_time - state['last_check'] >= LIVE_CHECK_INTERVAL:
        if VERBOSE_LOGGING:
            log(f"å¤„ç†ä¸­ï¼š{base_name}ï¼Œè¿›è¡Œå¢é‡æ£€æŸ¥...")
        check_live_folder_incremental(
            ts_dir, 
            state['checked_files'], 
            state['valid_files'], 
            state['error_logs']
        )
        state['last_check'] = current_time
    else:
        if DEBUG_MODE:
            remaining = LIVE_CHECK_INTERVAL - (current_time - state['last_check'])
            log(f"æ–‡ä»¶å¤¹ {base_name} ç­‰å¾… {remaining:.0f} ç§’åè¿›è¡Œä¸‹æ¬¡æ£€æŸ¥")
    
    return False  # ç›´æ’­è¿˜åœ¨è¿›è¡Œä¸­ï¼Œæ–‡ä»¶å¤¹æœªå®Œæˆ


def cleanup_old_folder_states(folder_states: dict, active_folders: list, current_time: float):
    """æ¸…ç†è¿‡æœŸçš„æ–‡ä»¶å¤¹çŠ¶æ€ï¼Œé‡Šæ”¾å†…å­˜"""
    folders_to_remove = []
    
    for folder_path, state in folder_states.items():
        # å¦‚æœæ–‡ä»¶å¤¹ä¸åœ¨æ´»åŠ¨åˆ—è¡¨ä¸­ï¼Œä¸”çŠ¶æ€ä¿ç•™æ—¶é—´è¶…è¿‡é…ç½®çš„å»¶è¿Ÿ
        if (folder_path not in active_folders and 
            current_time - state.get('last_check', 0) > FOLDER_CLEANUP_DELAY):
            folders_to_remove.append(folder_path)
        # å¦‚æœæ–‡ä»¶å¤¹å·²ç»æœ‰filelist.txtï¼Œå¼ºåˆ¶æ¸…ç†
        elif has_been_merged(folder_path):
            folders_to_remove.append(folder_path)
    
    for folder_path in folders_to_remove:
        if DEBUG_MODE:
            log(f"æ¸…ç†è¿‡æœŸæ–‡ä»¶å¤¹çŠ¶æ€: {folder_path.name}")
        del folder_states[folder_path]

def merge_worker():
    """ç‹¬ç«‹çš„åˆå¹¶å·¥ä½œçº¿ç¨‹ï¼Œä»é˜Ÿåˆ—ä¸­ä¸²è¡Œæ‰§è¡Œåˆå¹¶ä»»åŠ¡"""
    log("âœ¨ åˆå¹¶å·¥ä½œçº¿ç¨‹å·²å¯åŠ¨")
    
    while True:
        try:
            # ä»é˜Ÿåˆ—è·å–ä»»åŠ¡ï¼Œé˜»å¡ç­‰å¾…
            task = merge_queue.get()
            
            if task is None:  # None æ˜¯åœæ­¢ä¿¡å·
                log("åˆå¹¶å·¥ä½œçº¿ç¨‹æ”¶åˆ°åœæ­¢ä¿¡å·")
                break
            
            group_key, group_folders = task
            
            try:
                log(f"ğŸ”„ [åˆå¹¶é˜Ÿåˆ—] å¼€å§‹åˆå¹¶: {group_key}")
                earliest_folder = min(group_folders, key=lambda x: x.stat().st_ctime)
                merged_video = OUTPUT_DIR / f"{earliest_folder.name}{OUTPUT_EXTENSION}"
                
                if not merged_video.exists():
                    merge_once(target_folders=group_folders)
                    log(f"âœ… [åˆå¹¶é˜Ÿåˆ—] å®Œæˆ: {group_key}")
                else:
                    log(f"â­ï¸  [åˆå¹¶é˜Ÿåˆ—] æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {group_key}")
                    
            except Exception as e:
                log(f"âŒ [åˆå¹¶é˜Ÿåˆ—] å¤±è´¥ {group_key}: {e}")
                import traceback
                log(traceback.format_exc())
            finally:
                merge_queue.task_done()  # æ ‡è®°ä»»åŠ¡å®Œæˆ
                
        except Exception as e:
            log(f"åˆå¹¶å·¥ä½œçº¿ç¨‹å¼‚å¸¸: {e}")
            time.sleep(1)

# ========================= ä¸»å¾ªç¯ =========================

def main_loop():
    log("å¼€å§‹ç›‘æ§ç›´æ’­æ–‡ä»¶å¤¹...")
    
    # å¯åŠ¨åˆå¹¶å·¥ä½œçº¿ç¨‹
    merge_thread = Thread(target=merge_worker, daemon=True, name="MergeWorker")
    merge_thread.start()
    
    folder_states = {}
    subtitle_check_count = {}
    submitted_merges = set()  # æ·»åŠ è¿™è¡Œï¼šè¿½è¸ªå·²æäº¤åˆ°é˜Ÿåˆ—çš„ç»„
    
    try:
        while True:
            current_time = time.time()
            
            # è·å–ç›´æ’­æ–‡ä»¶å¤¹
            if PROCESS_ALL_FOLDERS:
                all_folders = find_all_live_folders(PARENT_DIR)
                all_folders = [f for f in all_folders if not has_been_merged(f)]

                # æŒ‰ç›´æ’­åˆ†ç»„åå†é™åˆ¶æ¯ç»„çš„æ–‡ä»¶å¤¹æ•°é‡
                if all_folders:
                    # å…ˆæŒ‰æˆå‘˜å’Œæ—¶é—´åˆ†ç»„
                    grouped = group_folders_by_member(all_folders)

                    # å¯¹æ¯ç»„é™åˆ¶æ–‡ä»¶å¤¹æ•°é‡(ä¿ç•™æœ€æ—©çš„æ–‡ä»¶å¤¹)
                    all_folders = []  # â† æ¸…ç©ºå‡†å¤‡é‡å»º
                    for group_key, group_folders in list(grouped.items()):
                        # æŒ‰åˆ›å»ºæ—¶é—´æ’åº(æœ€æ—©çš„åœ¨å‰)
                        group_folders.sort(key=lambda x: x.stat().st_ctime)

                        # å¦‚æœè¯¥ç»„è¶…è¿‡é™åˆ¶,åªå–æœ€æ—©çš„Nä¸ª
                        if len(group_folders) > MAX_CONCURRENT_FOLDERS_PER_LIVE:
                            if DEBUG_MODE:
                                log(f"ç›´æ’­ç»„ {group_key} æœ‰ {len(group_folders)} ä¸ªæ–‡ä»¶å¤¹,é™åˆ¶ä¸º {MAX_CONCURRENT_FOLDERS_PER_LIVE} ä¸ª")
                            group_folders = group_folders[:MAX_CONCURRENT_FOLDERS_PER_LIVE]
                            grouped[group_key] = group_folders  # â† æ›´æ–° grouped å­—å…¸

                        all_folders.extend(group_folders)  # â† é‡å»º all_folders
                else:
                    grouped = {}  # ç©ºå­—å…¸
            else:
                latest_folder = find_latest_live_folder(PARENT_DIR)
                if latest_folder and not has_been_merged(latest_folder):
                    all_folders = [latest_folder]
                    grouped = group_folders_by_member(all_folders)
                else:
                    all_folders = []
                    grouped = {}  # ç©ºå­—å…¸

            if not all_folders:
                if DEBUG_MODE:
                    log("æœªæ‰¾åˆ°ç›´æ’­æ–‡ä»¶å¤¹,ç­‰å¾…ä¸­...")
                time.sleep(CHECK_INTERVAL)
                continue
            
            # ==== ç›´æ¥è¿›å…¥æŒ‰ç»„å¤„ç†,ä¸éœ€è¦å…¨å±€åˆ¤æ–­ ====
            for group_key, group_folders in grouped.items():
                member_id = extract_member_name_from_folder(group_folders[0].name)
                
                # è¯¥ç»„çš„ç½‘ç»œçŠ¶æ€
                if member_id:
                    group_is_streaming = read_is_live(member_id)
                else:
                    group_is_streaming = False
                    if DEBUG_MODE:
                        log(f"æ— æ³•æå–æˆå‘˜ID: {group_key}")
                
                # è¯¥ç»„çš„æ–‡ä»¶æ´»è·ƒåº¦
                group_files_active = not is_really_stream_ended(group_folders, FINAL_INACTIVE_THRESHOLD)
                
                # --- æ–°çš„å­—å¹•æ£€æŸ¥å’Œåˆå¹¶é€»è¾‘ ---
                
                # 1. è·³è¿‡å·²ç»å®Œæˆåˆå¹¶çš„ç»„
                group_is_merged = all(has_been_merged(f) for f in group_folders)
                if group_is_merged:
                    continue  # è·³è¿‡è¯¥ç»„ï¼Œå¤„ç†ä¸‹ä¸€ä¸ª

                group_can_merge = False  # æ ‡è®°è¯¥ç»„æ˜¯å¦å¯ä»¥è¿›å…¥æœ€ç»ˆæ£€æŸ¥/åˆå¹¶æµç¨‹
                
                # 2. å¦‚æœç›´æ’­ç»“æŸä¸”æ–‡ä»¶å·²ç¨³å®š (è§¦å‘æœ€ç»ˆæ£€æŸ¥/åˆå¹¶çš„æ¡ä»¶)
                if not group_is_streaming and not group_files_active:
                    
                    # å¼€å§‹å­—å¹•æ£€æŸ¥è®¡æ•°å’Œå¼ºåˆ¶é€šè¿‡é€»è¾‘ (ä¸å†ä¾èµ– has_been_merged)
                    if group_key not in subtitle_check_count:
                        subtitle_check_count[group_key] = 0
                        
                    subtitle_check_count[group_key] += 1
                    group_has_subtitle = has_matching_subtitle_for_group(group_folders)
                    
                    # ã€å¼ºåˆ¶é€€å‡ºç­‰å¾…ã€‘å­—å¹•æœªæ‰¾åˆ°ï¼Œä½†æ£€æŸ¥æ¬¡æ•°è¾¾åˆ° 5 æ¬¡
                    if not group_has_subtitle and subtitle_check_count[group_key] >= 5:
                        log(f"å­—å¹•æ–‡ä»¶æ£€æŸ¥å·²è¾¾åˆ° {subtitle_check_count[group_key]} æ¬¡,åˆ¤å®šä¸ºæ— å­—å¹•è§†é¢‘: {group_key}")
                        group_has_subtitle = True  # å¼ºåˆ¶é€šè¿‡
                    
                    if group_has_subtitle:
                        group_can_merge = True  # å­—å¹•æ‰¾åˆ°æˆ–å·²å¼ºåˆ¶é€šè¿‡ï¼Œå…è®¸åˆå¹¶
                        log(f"[{group_key}] æ»¡è¶³åˆå¹¶æ¡ä»¶ (å­—å¹•æ‰¾åˆ°æˆ–è¶…æ—¶)ï¼Œå¼€å§‹æœ€ç»ˆæ£€æŸ¥ã€‚")
                    else:
                        # ä»åœ¨ç­‰å¾…å­—å¹•ï¼Œè®¡æ•°å™¨æœªè¾¾åˆ° 5 æ¬¡
                        log(f"[{group_key}] ç­‰å¾…å­—å¹•æ–‡ä»¶ç”Ÿæˆä¸­... (ç¬¬ {subtitle_check_count[group_key]} æ¬¡æ£€æŸ¥)")

                # 3. å¦‚æœæ»¡è¶³åˆå¹¶æ¡ä»¶ (group_can_merge)
                if group_can_merge:
                    
                    # (A) æœ€ç»ˆæ£€æŸ¥ (è°ƒç”¨ finalize_live_checkï¼Œæ­¤æ—¶ä¼šåˆ›å»º filelist.txt æ ‡è®°)
                    for ts_dir in group_folders:
                        if not has_been_merged(ts_dir):  # å†æ¬¡æ£€æŸ¥é˜²æ­¢é‡å¤æ“ä½œ
                            log(f"å¯¹å·²ç»“æŸçš„ç›´æ’­è¿›è¡Œæœ€ç»ˆæ£€æŸ¥: {ts_dir.name}")
                            # ç¡®ä¿ folder_states ä¸­æœ‰è¯¥æ–‡ä»¶å¤¹çš„çŠ¶æ€
                            if ts_dir not in folder_states:
                                folder_states[ts_dir] = {'checked_files': set(), 'valid_files': [], 'error_logs': []}
                            
                            finalize_live_check(
                                ts_dir,
                                folder_states[ts_dir]['checked_files'],
                                folder_states[ts_dir]['valid_files'],
                                folder_states[ts_dir]['error_logs']
                            )
                    # (B) åˆå¹¶è¯¥ç»„ - æäº¤åˆ°åˆå¹¶é˜Ÿåˆ—
                    if all(has_been_merged(f) for f in group_folders):
                        earliest_folder = min(group_folders, key=lambda x: x.stat().st_ctime)
                        merged_video = OUTPUT_DIR / f"{earliest_folder.name}{OUTPUT_EXTENSION}"

                        if not merged_video.exists():
                            log(f"ğŸ“‹ ç›´æ’­ç»„ {group_key} å·²å®Œæˆæ£€æŸ¥ï¼ŒåŠ å…¥åˆå¹¶é˜Ÿåˆ— (å½“å‰é˜Ÿåˆ—: {merge_queue.qsize()} ä¸ªä»»åŠ¡)")
                            merge_queue.put((group_key, group_folders))
                            submitted_merges.add(group_key)  # æ ‡è®°ä¸ºå·²æäº¤
                        else:
                            log(f"â­ï¸  ç›´æ’­ç»„ {group_key} åˆå¹¶æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡")

                # 4. å¦‚æœä»åœ¨ç›´æ’­/æ–‡ä»¶æ´»è·ƒï¼Œåˆ™ç»§ç»­æ‰§è¡Œå¢é‡æ£€æŸ¥
                elif group_is_streaming or group_files_active:
                    for ts_dir in group_folders:
                        if has_files_to_check(ts_dir) and not has_been_merged(ts_dir):
                            # ç›´æ¥è°ƒç”¨ process_single_folderï¼Œè®©å®ƒè‡ªå·±ç®¡ç† folder_states å­—å…¸ä¸­çš„çŠ¶æ€
                            process_single_folder(ts_dir, folder_states, all_folders, current_time)
            
            # æ¸…ç†è¿‡æœŸçŠ¶æ€
            cleanup_old_folder_states(folder_states, all_folders, current_time)
            
            # æ¸…ç†å­—å¹•æ£€æŸ¥è®¡æ•°å™¨
            active_group_keys = set(grouped.keys())

            # æ‰¾å‡ºä¸å†æ´»è·ƒçš„ group_key è¿›è¡Œæ¸…ç†
            keys_to_remove = [key for key in subtitle_check_count.keys() 
                              if key not in active_group_keys]
            
            for key in keys_to_remove:
                if DEBUG_MODE:
                    log(f"æ¸…ç†å­—å¹•è®¡æ•°å™¨ä¸­å·²å®Œæˆ/ä¸æ´»è·ƒçš„ç»„: {key}")
                del subtitle_check_count[key]
                # åŒæ—¶æ¸…ç†å·²æäº¤çš„åˆå¹¶è®°å½•
                if key in submitted_merges:
                    submitted_merges.discard(key)
            
            time.sleep(CHECK_INTERVAL)
            
    except KeyboardInterrupt:
        log("æ”¶åˆ°åœæ­¢ä¿¡å·,ç­‰å¾…åˆå¹¶é˜Ÿåˆ—å®Œæˆ...")
        merge_queue.join()  # ç­‰å¾…æ‰€æœ‰åˆå¹¶ä»»åŠ¡å®Œæˆ
        merge_queue.put(None)  # å‘é€åœæ­¢ä¿¡å·
        log("ç¨‹åºé€€å‡º")
    except Exception as e:
        log(f"ä¸»å¾ªç¯å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        log(traceback.format_exc())

if __name__ == "__main__":
    main_loop()