import os
import time
import logging
import sys
import cx_Oracle
import asyncio
import httpx
import random
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent))
sys.path.insert(0, str(Path(__file__).parent.parent / "shared"))
from datetime import datetime
from queue import Queue
from threading import Thread
from logger_config import setup_logger

# ============================================================
# åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿï¼ˆå¿…é¡»åœ¨ config ä¹‹å‰ï¼ï¼‰
# ============================================================
setup_logger()

# ============================================================
# å¯¼å…¥ä¾èµ–ï¼ˆåœ¨æ—¥å¿—åˆå§‹åŒ–ä¹‹åï¼‰
# ============================================================
from config import *
from load_balancer_module import LoadBalancer

# ==== é…ç½® ====
logging.getLogger("httpx").setLevel(logging.WARNING)
os.environ["TNS_ADMIN"] = WALLET_DIR
sys.path.insert(0, str(Path(__file__).parent))

# ============================================
# æˆå‘˜åˆ—è¡¨åˆå§‹åŒ–é€»è¾‘
# ============================================
INSTANCE_ID = os.getenv("INSTANCE_ID")
MEMBER_ID = sys.argv[1] if len(sys.argv) > 1 else os.getenv("MEMBER_ID")

# æ¨¡å¼1: å¤šæ£€æµ‹å™¨å®ä¾‹æ¨¡å¼ï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰
if INSTANCE_ID:
    # ä»å®ä¾‹IDæå–ç´¢å¼• (monitor-a â†’ 0, monitor-b â†’ 1, ...)
    instance_index = ord(INSTANCE_ID[-1]) - ord('a')
    
    # âœ… è‡ªåŠ¨ä»æ•°æ®åº“æŸ¥è¯¢æ£€æµ‹å™¨å®ä¾‹æ€»æ•°
    try:
        conn = get_db_connection()
        if conn:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT COUNT(*) 
                FROM ADMIN.INSTANCES 
                WHERE INSTANCE_TYPE = 'monitor' 
                  AND STATUS = 'active'
            """)
            instance_count = cursor.fetchone()[0]
            cursor.close()
            conn.close()
            
            if instance_count == 0:
                print(f"âš ï¸  è­¦å‘Š: æ•°æ®åº“ä¸­æ²¡æœ‰æ´»è·ƒçš„æ£€æµ‹å™¨å®ä¾‹ï¼Œä½¿ç”¨å•å®ä¾‹æ¨¡å¼")
                instance_count = 1
        else:
            print(f"âš ï¸  è­¦å‘Š: æ— æ³•è¿æ¥æ•°æ®åº“ï¼Œä½¿ç”¨å•å®ä¾‹æ¨¡å¼")
            instance_count = 1
    except Exception as e:
        print(f"âš ï¸  è­¦å‘Š: æŸ¥è¯¢å®ä¾‹æ•°å¤±è´¥ ({e})ï¼Œä½¿ç”¨å•å®ä¾‹æ¨¡å¼")
        instance_count = 1
    
    # å•å®ä¾‹æ¨¡å¼ï¼ˆåªæœ‰1å°æ£€æµ‹å™¨ï¼‰
    if instance_count == 1:
        MEMBERS = ENABLED_MEMBERS
        print(f"âœ… å•æ£€æµ‹å™¨æ¨¡å¼: {INSTANCE_ID}")
        print(f"   ç›‘æ§æ‰€æœ‰æˆå‘˜: {len(MEMBERS)} ä¸ª")
    
    # å¤šå®ä¾‹æ¨¡å¼ï¼ˆ2å°æˆ–æ›´å¤šï¼‰
    else:
        if instance_index >= instance_count:
            print(f"âŒ é”™è¯¯: å®ä¾‹ç´¢å¼• {instance_index} è¶…å‡ºèŒƒå›´")
            print(f"   å½“å‰æ´»è·ƒå®ä¾‹æ•°: {instance_count}")
            print(f"   è¯·ä½¿ç”¨ monitor-a åˆ° monitor-{chr(ord('a') + instance_count - 1)}")
            sys.exit(1)
        
        # è®¡ç®—åˆ†é…èŒƒå›´
        all_members = ENABLED_MEMBERS
        chunk_size = len(all_members) // instance_count
        
        start = instance_index * chunk_size
        # æœ€åä¸€ä¸ªå®ä¾‹åŒ…å«æ‰€æœ‰å‰©ä½™æˆå‘˜
        end = start + chunk_size if instance_index < instance_count - 1 else len(all_members)
        
        MEMBERS = all_members[start:end]
        
        print(f"ğŸ”€ å¤šæ£€æµ‹å™¨æ¨¡å¼: {INSTANCE_ID}")
        print(f"   æ€»å®ä¾‹æ•°: {instance_count} (è‡ªåŠ¨æ£€æµ‹)")
        print(f"   æœ¬å®ä¾‹è´Ÿè´£: {len(MEMBERS)} ä¸ªæˆå‘˜ (ç¬¬ {start+1}-{end} ä¸ª)")
        print(f"   æˆå‘˜ç¤ºä¾‹: {', '.join(m['id'] for m in MEMBERS[:3])}{'...' if len(MEMBERS) > 3 else ''}")

# æ¨¡å¼2: ä¼ ç»Ÿæ¨¡å¼ï¼ˆå‘åå…¼å®¹ï¼‰
elif MEMBER_ID:
    if MEMBER_ID.upper() == "ALL":
        MEMBERS = ENABLED_MEMBERS
        print(f"âœ… ä¼ ç»Ÿæ¨¡å¼: ç›‘æ§æ‰€æœ‰æˆå‘˜ ({len(MEMBERS)} ä¸ª)")
    else:
        MEMBER = next((m for m in ENABLED_MEMBERS if m["id"] == MEMBER_ID), None)
        if not MEMBER:
            print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æˆå‘˜ ID: {MEMBER_ID}")
            print(f"   å¯ç”¨çš„æˆå‘˜: {', '.join(m['id'] for m in ENABLED_MEMBERS)}, ALL")
            sys.exit(1)
        MEMBERS = [MEMBER]
        print(f"âœ… å•æˆå‘˜æ¨¡å¼: ç›‘æ§ {MEMBER['id']}")
else:
    MEMBERS = [ENABLED_MEMBERS[0]]
    print(f"âš ï¸  æœªæŒ‡å®šæˆå‘˜ï¼Œä½¿ç”¨é»˜è®¤: {MEMBERS[0]['id']}")

# ==== æ•°æ®åº“é˜Ÿåˆ— (ä¸éœ€è¦é”äº†,å› ä¸ºå¼‚æ­¥æ˜¯å•çº¿ç¨‹) ====
db_queue = Queue(maxsize=1000)

# ==== æ•°æ®åº“è¿æ¥ ====
def save_to_db(member_id, room_id, is_live_flag, started_at, prev_status, member):
    """å°†æ•°æ®æ”¾å…¥é˜Ÿåˆ—,ç”±ä¸“é—¨çº¿ç¨‹å†™å…¥æ•°æ®åº“"""
    db_queue.put({
        'member_id': member_id,
        'room_id': room_id,
        'is_live_flag': is_live_flag,
        'started_at': started_at,
        'prev_is_live': prev_status.get(member_id, {}).get('is_live', False),
        'group_name': member.get('group_name', ''),
        'team_name': member.get('team_name', '')
    })
    return True

def db_writer_thread(stop_flag):
    logging.info("[DB-Writer] ğŸš€ æ•°æ®åº“å†™å…¥çº¿ç¨‹å¯åŠ¨ (å®æ—¶å…¨é‡æ¨¡å¼)")
    conn = get_db_connection()
    cursor = None
    # âœ… æ–°å¢ï¼šåˆå§‹åŒ–è´Ÿè½½å‡è¡¡å™¨ï¼ˆç”¨äºç»™å½•åˆ¶å™¨åˆ†é…ï¼‰
    load_balancer = LoadBalancer(conn)
    # æ–°å¢ï¼šç”¨äºç»Ÿè®¡æ—¥å¿—çš„å˜é‡
    total_processed_in_round = 0
    last_log_time = time.time()

    # âœ… ä¼˜åŒ–ï¼šå°† SQL è¯­å¥å®šä¹‰åœ¨å¾ªç¯å¤–ï¼Œä½¿ç”¨ç»‘å®šå˜é‡ï¼Œæé«˜è§£ææ•ˆç‡
    merge_sql = f"""
        MERGE /*+ NO_PARALLEL */ INTO {DB_TABLE} target
        USING (SELECT :member_id_param AS MEMBER_ID_VAL FROM DUAL) source
        ON (target.MEMBER_ID = source.MEMBER_ID_VAL)
        WHEN MATCHED THEN
            UPDATE SET ROOM_ID = :room_id_param, IS_LIVE = :live_flag_param,
                       STARTED_AT = NVL(:started_at_param, target.STARTED_AT), 
                       CHECK_TIME = :check_time_param, GROUP_NAME = :group_name_param, TEAM_NAME = :team_name_param
        WHEN NOT MATCHED THEN
            INSERT (MEMBER_ID, ROOM_ID, IS_LIVE, STARTED_AT, CHECK_TIME, GROUP_NAME, TEAM_NAME)
            VALUES (:member_id_param, :room_id_param, :live_flag_param, :started_at_param, :check_time_param, :group_name_param, :team_name_param)
    """
    
    insert_history_sql = f"INSERT INTO {DB_HISTORY_TABLE} (MEMBER_ID, ROOM_ID, STARTED_AT) VALUES (:member_id, :room_id, :started_at)"
    
    update_history_sql = f"""
        UPDATE {DB_HISTORY_TABLE}
        SET ENDED_AT = :ended_at,
            DURATION_MINUTES = ROUND(EXTRACT(DAY FROM (:ended_at - STARTED_AT)) * 1440 + EXTRACT(HOUR FROM (:ended_at - STARTED_AT)) * 60 + EXTRACT(MINUTE FROM (:ended_at - STARTED_AT)) + EXTRACT(SECOND FROM (:ended_at - STARTED_AT)) / 60, 2),
            UPDATED_AT = SYSTIMESTAMP
        WHERE ID = (SELECT MAX(ID) FROM {DB_HISTORY_TABLE} WHERE MEMBER_ID = :member_id AND ENDED_AT IS NULL)
    """

    while not stop_flag[0] or not db_queue.empty():
        try:
            # 1. é˜»å¡ç­‰å¾…é˜Ÿåˆ—ä¸­çš„ç¬¬ä¸€ä¸ªæ•°æ®ï¼Œè¶…æ—¶ 1 ç§’
            data = db_queue.get(timeout=1.0)
            batch_buffer = [data]

            # 2. ã€æ ¸å¿ƒã€‘ç¬é—´æ’ç©ºé˜Ÿåˆ—é‡Œå‰©ä½™çš„æ‰€æœ‰æ•°æ® (è¿™ 277 æ¡ä¼šç¬é—´è¢«æ‹¿å‡ºæ¥)
            while not db_queue.empty():
                try:
                    batch_buffer.append(db_queue.get_nowait())
                except:
                    break
            
            # 3. æŒ‰ member_id å»é‡ï¼Œåªä¿ç•™æœ¬è½®æœ€æ–°çš„çŠ¶æ€
            unique_buffer = {d['member_id']: d for d in batch_buffer}
            final_list = list(unique_buffer.values())

            # 4. æ‰§è¡Œæ‰¹é‡æ“ä½œ
            if final_list and conn:
                if cursor is None: cursor = conn.cursor()
                
                all_bind_params = []
                history_inserts = []
                history_updates = []
                check_time = datetime.now()

                for d in final_list:
                    all_bind_params.append({
                        'member_id_param': d['member_id'],
                        'room_id_param': d['room_id'],
                        'live_flag_param': 1 if d['is_live_flag'] else 0,
                        'started_at_param': d['started_at'],
                        'check_time_param': check_time,
                        'group_name_param': d['group_name'],
                        'team_name_param': d['team_name']
                    })
                    # å†å²è¡¨é€»è¾‘
                    if d['is_live_flag'] and not d['prev_is_live']:
                        # å¼€æ’­ï¼šæ’å…¥å†å²è®°å½•
                        history_inserts.append({
                            'member_id': d['member_id'], 
                            'room_id': d['room_id'], 
                            'started_at': d['started_at']
                        })
                        
                        # âœ… æ–°å¢ï¼šç«‹å³åˆ†é…å½•åˆ¶å™¨
                        try:
                            recorder_id = load_balancer.assign_recorder(d['member_id'])
                            if recorder_id:
                                logging.info(f"[åˆ†é…] {d['member_id']} â†’ {recorder_id}")
                        except Exception as e:
                            logging.error(f"[åˆ†é…å¤±è´¥] {d['member_id']}: {e}")
                    
                    elif not d['is_live_flag'] and d['prev_is_live']:
                        # ä¸‹æ’­ï¼šæ›´æ–°å†å²è®°å½•
                        history_updates.append({
                            'ended_at': check_time, 
                            'member_id': d['member_id']
                        })
                        
                        # âœ… æ–°å¢ï¼šæ¸…é™¤åˆ†é…
                        try:
                            load_balancer.clear_assignment(d['member_id'])
                            logging.debug(f"[æ¸…é™¤åˆ†é…] {d['member_id']}")
                        except Exception as e:
                            logging.error(f"[æ¸…é™¤å¤±è´¥] {d['member_id']}: {e}")

                # 5. ä¸€æ¬¡æ€§å†™å…¥å¹¶æäº¤ (è¿™æ˜¯ 277 æ¡æ•°æ®æœ€å¿«çš„å…¥åº“æ–¹å¼)
                cursor.executemany(merge_sql, all_bind_params)
                if history_inserts: cursor.executemany(insert_history_sql, history_inserts)
                if history_updates: cursor.executemany(update_history_sql, history_updates)
                
                conn.commit()
                # âœ… ç´¯åŠ å¤„ç†æ•°é‡ï¼Œä½†ä¸ç«‹åˆ»æ‰“æ—¥å¿—
                total_processed_in_round += len(final_list)
                
            # 4. é‡ç‚¹ï¼šåˆ¤æ–­æ˜¯å¦è¾¾åˆ° 5 ç§’çš„æ—¥å¿—å‘¨æœŸ
            current_time = time.time()
            if current_time - last_log_time >= 5.0:
                if total_processed_in_round > 0:
                    logging.info(f"âœ… [å‘¨æœŸæ±‡æ€»] è¿‡å» 5 ç§’å†…å®æ—¶å…¥åº“å…±è®¡: {total_processed_in_round} æ¡è®°å½•")
                # é‡ç½®è®¡æ•°å™¨
                total_processed_in_round = 0
                last_log_time = current_time
            # æ ‡è®°å®Œæˆ
            for _ in range(len(batch_buffer)):
                db_queue.task_done()
                
        except Exception as e:
            if 'data' in locals(): # é¿å… timeout å¯¼è‡´çš„å¼‚å¸¸
                logging.error(f"æ•°æ®åº“å†™å…¥é”™è¯¯: {e}")
                if conn: conn.rollback()
            continue

    # âœ… while å¾ªç¯ç»“æŸåï¼Œçº¿ç¨‹é€€å‡ºå‰å¤„ç†å‰©ä½™æ•°æ®
    if batch_buffer and conn and cursor:
        try:
            logging.info(f"[DB-Writer] ğŸ”„ å¤„ç†é€€å‡ºå‰å‰©ä½™çš„ {len(batch_buffer)} æ¡æ•°æ®")
            # âœ… åœ¨å¾ªç¯å¤–å‡†å¤‡æ‰¹é‡å‚æ•°åˆ—è¡¨
            all_bind_params = []
            history_inserts = []
            history_updates = []

            for data in batch_buffer:
                member_id = data['member_id']
                room_id = data['room_id']
                is_live_flag = data['is_live_flag']
                started_at = data['started_at']
                prev_is_live = data['prev_is_live']
                check_time = datetime.now()
                
                # æ”¶é›†ä¸»è¡¨å‚æ•°
                all_bind_params.append({
                    'member_id_param': member_id,
                    'room_id_param': room_id,
                    'live_flag_param': 1 if is_live_flag else 0,
                    'started_at_param': started_at,
                    'check_time_param': check_time,
                    'group_name_param': data['group_name'],
                    'team_name_param': data['team_name']
                })
                
                # æ”¶é›†å†å²è¡¨æ“ä½œ
                if is_live_flag and not prev_is_live:
                    history_inserts.append({
                        'member_id': member_id,
                        'room_id': room_id,
                        'started_at': started_at
                    })
                    
                    # âœ… æ–°å¢ï¼šåˆ†é…å½•åˆ¶å™¨
                    try:
                        recorder_id = load_balancer.assign_recorder(member_id)
                        if recorder_id:
                            logging.info(f"[é€€å‡ºå‰åˆ†é…] {member_id} â†’ {recorder_id}")
                    except Exception as e:
                        logging.error(f"[é€€å‡ºå‰åˆ†é…å¤±è´¥] {member_id}: {e}")
                        
                elif not is_live_flag and prev_is_live:
                    history_updates.append({
                        'ended_at': check_time,
                        'member_id': member_id
                    })
                    
                    # âœ… æ–°å¢ï¼šæ¸…é™¤åˆ†é…
                    try:
                        load_balancer.clear_assignment(member_id)
                    except Exception as e:
                        logging.error(f"[é€€å‡ºå‰æ¸…é™¤å¤±è´¥] {member_id}: {e}")

            # âœ… æ‰¹é‡æ‰§è¡Œ - åªè°ƒç”¨ä¸€æ¬¡!
            if all_bind_params:
                cursor.executemany(merge_sql, all_bind_params)
            
            if history_inserts:
                cursor.executemany(insert_history_sql, history_inserts)
                logging.info(f"æ‰¹é‡æ’å…¥ {len(history_inserts)} æ¡å¼€æ’­è®°å½•")
            
            if history_updates:
                cursor.executemany(update_history_sql, history_updates)
                logging.info(f"æ‰¹é‡æ›´æ–° {len(history_updates)} æ¡ç»“æŸè®°å½•")
            
            conn.commit()
            logging.info(f"[DB-Writer] âœ… é€€å‡ºå‰æäº¤å‰©ä½™ {len(batch_buffer)} æ¡")
        except Exception as e:
            logging.error(f"é€€å‡ºå‰æäº¤å¤±è´¥: {e}")
    
    # âœ… çº¿ç¨‹é€€å‡ºæ—¶æ¸…ç†èµ„æº
    if cursor:
        try:
            cursor.close()
        except:
            pass
    if conn:
        try:
            conn.close()
        except:
            pass
    
    logging.info("[DB-Writer] æ•°æ®åº“å†™å…¥çº¿ç¨‹å·²åœæ­¢")

# ==== å¼‚æ­¥HTTPè¯·æ±‚ ====
async def is_live_async(member_id, room_url_key, client):
    """å¼‚æ­¥æ£€æŸ¥ç›´æ’­çŠ¶æ€"""
    url = f"https://www.showroom-live.com/api/room/status?room_url_key={room_url_key}"

    try:
        res = await client.get(url)
        if res.status_code != 200:
            logging.warning(f"[{member_id}] è¯·æ±‚å¼‚å¸¸: {res.status_code}")
            return None, None
        
        try:
            data = res.json()
        except ValueError:
            logging.warning(f"[{member_id}] è¿”å›éJSONå†…å®¹,å¯èƒ½è¢«é™æµ")
            return None, None

        is_live_flag = data.get("is_live", False)
        started_at_raw = data.get("started_at") if is_live_flag else None
        
        if started_at_raw:
            started_at = datetime.fromtimestamp(started_at_raw)
        else:
            started_at = None
        
        return is_live_flag, started_at
    except Exception as e:
        logging.exception(f"[{member_id}] è·å–ç›´æ’­çŠ¶æ€å¤±è´¥")
        return False, None

def generate_key(member):
    """ç”Ÿæˆroom_url_key"""
    name_en = member.get("name_en", "")
    parts = name_en.split(" ")
    if len(parts) == 2:
        key_suffix = f"{parts[1]}_{parts[0]}" 
    else:
        key_suffix = name_en.replace(" ", "_")
    return f"48_{key_suffix}"

async def check_single_member(member, client, previous_status, last_db_write_time):
    member_id = member["id"]
    room_id = member["room_id"]
    name_jp = member["name_jp"]
    room_url_key = member.get("room_url_key") or generate_key(member)
    
    # 1. å¼‚æ­¥è·å–å½“å‰ç›´æ’­çŠ¶æ€
    is_live_flag, started_at = await is_live_async(member_id, room_url_key, client)
    
    if is_live_flag is not None:
        # è·å–ä¸Šä¸€æ¬¡çš„çŠ¶æ€
        prev_record = previous_status.get(member_id, {})
        
        # ç›´æ¥å†™å…¥æ•°æ®åº“ï¼Œä¸å†åˆ¤æ–­ 60 ç§’å¿ƒè·³
        save_to_db(member_id, room_id, is_live_flag, started_at, previous_status, member)
        
        # æ›´æ–°å†…å­˜çŠ¶æ€
        previous_status[member_id] = {'is_live': is_live_flag, 'started_at': started_at}

async def check_all_members_async(members, ip_clients, previous_status, last_db_write_time):
    """
    åŠ¨æ€å¹³æ»‘å¹¶å‘ï¼šç¡®ä¿è¯·æ±‚åœ¨å‡åŒ€åˆ†å¸ƒï¼Œä¸”æ¯ä¸ª IP ç¬æ—¶åªè´Ÿè´£ä¸€ä¸ªæˆå‘˜
    """
    total_members = len(members)
    if total_members == 0:
        return

    # 1. è®¡ç®—æ­¥è¿›é—´éš”
    target_fill_time = (REQUEST_INTERVAL - 0.1)
    interval = target_fill_time / total_members

    # 2. é™åˆ¶æ€»å¹¶å‘æ•°ä¸º IP æ•°é‡ï¼Œç¡®ä¿èµ„æºä¸è¶…è½½
    sem = asyncio.Semaphore(len(ip_clients))

    # 3. ã€å…³é”®ã€‘æ¯ä¸€è½®éƒ½ç”Ÿæˆä¸€ä¸ªéšæœºé¡ºåºçš„ IP å®¢æˆ·ç«¯åˆ—è¡¨
    # è¿™æ ·å¯ä»¥æ‰“ç ´â€œæˆå‘˜A æ°¸è¿œç”¨ IP_1â€çš„å›ºå®šå…³ç³»
    shuffled_clients = ip_clients.copy()
    random.shuffle(shuffled_clients)

    async def throttled_check(member, client, index):
        # æŒ‰è®¡ç®—å¥½çš„æ—¶é—´ç‚¹å‡ºå‘ï¼Œå®ç°å¹³æ»‘è¯·æ±‚
        await asyncio.sleep(index * interval)
        
        async with sem:
            # åœ¨ä¿¡å·é‡ä¿æŠ¤ä¸‹ï¼Œç”±äº client æ˜¯æŒ‰ index % len åˆ†é…çš„ï¼Œ
            # é…åˆä¿¡å·é‡å¤§å°ç­‰äº IP æ€»æ•°ï¼Œå¯ä»¥ä¿è¯æ­¤æ—¶è¯¥ IP æ²¡æœ‰è¢«å…¶ä»–ä»»åŠ¡å ç”¨
            return await check_single_member(member, client, previous_status, last_db_write_time)

    tasks = []
    num_ips = len(shuffled_clients)
    
    for i, member in enumerate(members):
        # 4. ã€æ ¸å¿ƒã€‘ä½¿ç”¨æ‰“ä¹±åçš„ IP åˆ—è¡¨è¿›è¡Œè½®è¯¢
        # å‡è®¾æœ‰ 30 ä¸ª IPï¼Œé‚£ä¹ˆ i=0..29 æ—¶ï¼Œæ¯ä¸ªæˆå‘˜åˆ†é…åˆ°çš„ IP ç»å¯¹ä¸é‡å¤
        client = shuffled_clients[i % num_ips]
        tasks.append(throttled_check(member, client, i))

    # å¹¶å‘æ‰§è¡Œ
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # é”™è¯¯ç»Ÿè®¡
    errors = [r for r in results if isinstance(r, Exception)]
    if errors:
        logging.warning(f"æœ¬è½®å®Œæˆï¼Œå…¶ä¸­ {len(errors)} ä¸ªè¯·æ±‚å‘ç”Ÿä»£ç çº§å¼‚å¸¸")

async def monitor_loop_async():
    """å¼‚æ­¥ä¸»å¾ªç¯"""
    global MEMBERS
    logging.info(f"ğŸš€ å¼€å§‹ç›‘è§† {len(MEMBERS)} ä¸ªä¸»æ’­ (å¼‚æ­¥æ¨¡å¼)")
    
    previous_status = {}
    last_db_write_time = {}
    stop_flag = [False]

    # âœ… é¢„å¤„ç†æ‰€æœ‰æˆå‘˜çš„teamä¿¡æ¯
    for member in MEMBERS:
        team_full = member.get("team", "")
        team_parts = team_full.split(" ", 1)
        member['group_name'] = team_parts[0] if len(team_parts) > 0 else ""
        member['team_name'] = team_parts[1] if len(team_parts) > 1 else ""
    
    # âœ… ç›´æ¥åˆ›å»ºå®¢æˆ·ç«¯åˆ—è¡¨
    ip_clients = []

    for ip in OUTBOUND_IPS:
        client = httpx.AsyncClient(
            transport=httpx.AsyncHTTPTransport(local_address=ip),
            timeout=10.0,
            limits=httpx.Limits(max_connections=20, max_keepalive_connections=15)
        )
        client._bound_ip = ip
        ip_clients.append(client)
    
    logging.info(f"âœ… åˆ›å»º {len(ip_clients)} ä¸ªå¼‚æ­¥HTTPå®¢æˆ·ç«¯")
    logging.info(f"ğŸ“Š é…ç½®ä¿¡æ¯:")
    logging.info(f"   æ€»æˆå‘˜: {len(MEMBERS)}")
    logging.info(f"   IPæ± å¤§å°: {len(OUTBOUND_IPS)}")
    logging.info(f"   å¹¶å‘è¯·æ±‚æ•°: {len(MEMBERS)}")
    
    # å¯åŠ¨DBçº¿ç¨‹
    db_thread = Thread(
        target=db_writer_thread,
        args=(stop_flag,),
        name="DB-Writer",
        daemon=True
    )
    db_thread.start()
    
    # ä¸»å¾ªç¯ç›‘æ§
    try:
        loop_count = 0
        while not stop_flag[0]:
            round_start = time.time()
            
            # é‡æ–°åŠ è½½æˆå‘˜é…ç½®
            try:
                from config import get_enabled_members
                all_members = get_enabled_members()
                if all_members:
                    MEMBERS = all_members
                    # âœ… é‡æ–°åŠ è½½åä¹Ÿé¢„å¤„ç†teamä¿¡æ¯
                    for member in MEMBERS:
                        team_full = member.get("team", "")
                        team_parts = team_full.split(" ", 1)
                        member['group_name'] = team_parts[0] if len(team_parts) > 0 else ""
                        member['team_name'] = team_parts[1] if len(team_parts) > 1 else ""
            except Exception as e:
                logging.error(f"é‡æ–°åŠ è½½æˆå‘˜é…ç½®å¤±è´¥: {e}")
            
            # âœ… å®šæœŸæ¸…ç†è¿‡æœŸçŠ¶æ€ (æ¯100è½®)
            if loop_count % 100 == 0 and loop_count > 0:
                current_ids = {m['id'] for m in MEMBERS}
                old_count = len(previous_status)
                previous_status = {k: v for k, v in previous_status.items() if k in current_ids}
                last_db_write_time = {k: v for k, v in last_db_write_time.items() if k in current_ids}
                if old_count > len(previous_status):
                    logging.info(f"ğŸ§¹ æ¸…ç†äº† {old_count - len(previous_status)} ä¸ªè¿‡æœŸçŠ¶æ€")
            
            # å¹¶å‘æ£€æµ‹æ‰€æœ‰æˆå‘˜
            await check_all_members_async(MEMBERS, ip_clients, previous_status, last_db_write_time)
            
            round_time = time.time() - round_start
            loop_count += 1

            if round_time < REQUEST_INTERVAL:
                await asyncio.sleep(REQUEST_INTERVAL - round_time)

            queue_size = db_queue.qsize()
            logging.info(f"â±ï¸ è½®è¯¢å®Œæˆ:è€—æ—¶ {round_time:.2f} ç§’ | é˜Ÿåˆ—: {queue_size}")
            
            if queue_size > 800:
                logging.warning(f"âš ï¸ é˜Ÿåˆ—å †ç§¯: {queue_size}/1000")
                
    except KeyboardInterrupt:
        logging.info("æ”¶åˆ°åœæ­¢ä¿¡å·...")
    except Exception as e:
        logging.error(f"ä¸»å¾ªç¯å¼‚å¸¸: {e}", exc_info=True)
    finally:
        stop_flag[0] = True
        
        logging.info("ç­‰å¾…æ•°æ®åº“é˜Ÿåˆ—æ¸…ç©º...")
        try:
            db_queue.join()
            logging.info("âœ… é˜Ÿåˆ—å·²æ¸…ç©º")
        except Exception as e:
            logging.warning(f"âš ï¸ é˜Ÿåˆ—æ¸…ç©ºå¤±è´¥: {e}")
        
        db_thread.join(timeout=10)
        if db_thread.is_alive():
            logging.warning("âš ï¸ DBçº¿ç¨‹æœªèƒ½æ­£å¸¸é€€å‡º")
        
        # âœ… å…³é—­æ‰€æœ‰å¼‚æ­¥å®¢æˆ·ç«¯
        logging.info("å…³é—­HTTPå®¢æˆ·ç«¯...")
        for client in ip_clients:
            try:
                await client.aclose()
            except Exception as e:
                logging.error(f"å…³é—­å®¢æˆ·ç«¯å¤±è´¥: {e}")
        
        logging.info("æ‰€æœ‰ä»»åŠ¡å·²åœæ­¢")

if __name__ == "__main__":
    try:
        asyncio.run(monitor_loop_async())
    except KeyboardInterrupt:
        # è¿™é‡Œä»€ä¹ˆéƒ½ä¸å†™ï¼Œæˆ–è€…åªæ‰“å°ä¸€è¡Œç®€å•çš„é€€å‡ºæç¤º
        pass